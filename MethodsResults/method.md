
# Method & Result: Exploring user behavior patterns based on Zhihu dataset - a Chinese online Q&A community

#### Andi Liao

## 1. Data Section

### 1.1 Data Collection

The Zhihu user dataset used in this research comes from a public GitHub repository https://github.com/MatrixSeven/ZhihuSpider, where the owner kindly shared the web-scraping data generated by his own ZhihuSpider. The spider is written in Java, and the original dataset of 420962 users is in MySQL format.

The data collection process is relatively simple for this study - I directly downloaded the dataset from the repository, and star the contributor as he hoped.

### 1.2 Data Structure

The dataset contains three tables: follower, users, and users_info. After omitting repeated and irrelevant variables, only part of these three tables are used in this research. Below is the summary:

##### Table 1.2 Summary of variables in dataset

| Table      | Variable      | Variable Description  |
| :--------: | :-----------: | :-------------------: |
| follower   | user          | The user name         |
|            | follower      | The user's follower name |
| users      | id            | The unique id of user  |
|            | from_id       | The user id which the current user is following |
|users_info  | name          | The user name           |
|            | address       | The location/base       |
|            | education     | The education level     |
|            | company       | The working company     |
|            | job           | The occupation          |
|            | headline      | The motto of user       |   |            | user_id       | The unique id of user   |
|            | answer        | Number of answers the user provided |
|            | question      | Number of questions the user asked |
|            | article       | Number of articles the user wrote |
|            | favorite      | Number of answers the user starred |
|            | agree         | Number of upvotes the user received for answers |
|            | thanked       | Number of thanks the user received for answers |
|            | following     | Number of users the user is following |
|            | followers     | Number of followers the user has |
|            | topic         | Number of topics the user is following |
|            | columns       | Number of columns the user is following |
|            | sex           | Gender                   |
|            | weibo         | The weibo address of the user |
|            | index_url     | The profile link of the user|


### 1.3 Data Preprocessing

There are four main steps in data preprocessing:
* transform data from MySQL to csv format;
* reserve selected variables;
* handle missing data;
* convert text data into categorical type.

It is worth noticing that there are lots of missing data in selected variables. Some of them are missing when scraping the profile, therefore, I filter this subset of records as missing indicate inactivity in this case. However, the other part of the missing data is because that user prefer not to demonstrate personal information, so I treat NA values as a special category rather than ignoring them.

The purpose of converting text data is to utilize available data to the maximum extent. As I won't use natural language processing methods in classifying expert users, it would be better to convert them into categorical variable so that they can be useful features in modelling.

After preprocessing, there remains 420949 unique user ids for analysis.


## 2. Method

### 2.1 K-Means Clustering

To observe the general pattern of user groups, I first implement a unsupervised learning method, K-Means clustering. I expected to see users can be divided into at least two meaningful clusters, expert user and non-expert users.

### 2.2 Adding Labels

In order to perform random forest classification, a supervised learning method, the next step is to add "expert" label for each user.

Zhihu adopts an unconventional verified-user policy: every user can provide identity proof materials and apply for the verified symbol. Some of the expert users haven't applied for the verified symbol yet, still, they are recognized as expert users. Therefore, the verified symbol is not equivalent to the user's expertise, and other data sources are necessary for mapping labels to users.

A "H-index" will be introduced instead of official personal verified symbol for measuring user expertise. The _h-index_ is defined as: at least _h_ number of _answers_ of this user received at least h number of _agreed_ , which is similar to the _h-index_ in academics.

Inside Zhihu community, the _h-index_ is considered as a more accurate measurement for user contribution unofficially. Additionally, a top 1000 user name list based on _h-index_, calculating at 2016, is modified, discussed and released by _excellent users_ in the programming area under this topic. The top _h-index_ list is the basis of "expert" label adding process.

In this study, I divide the dataset into training, validation and test set, and only the record in training and validation set will be labeled.

Refernece:https://www.zhihu.com/question/31273136/answer/106466841

### 2.3 Random Forest Classification and Prediction

The final part of this research is perform random forest classification using trainin


## 3. Result

Below is a screenshot of the dataset after cleaning, including all the variables that will be used in the analysis.

![](.png)

### 3.1 Summary Statistics for Key Variables

#### 3.1.1 Demographical Information

Gender, headline and weibo are viewed as demographical information in this study. Headline and weibo are chosen here as they can be treated as binary variables, which are ideal for modelling. Among the dataset, 83.31% of users claim as "male", and rest of them are "female"; 60.60% of users have headline, but others don't; 21.79% of users display their weibo account url, while others don't.

Due to the massive amount of missing data, address, education, company and job will not enter the following data analysis process. Still, a brief summary is provided here to see the typical user profile of this Zhihu dataset.

##### Table 3.1.1 Top item of address, education, company and job
| Variable | Item | Count |
| :------: | :--: | :---: |
| address  | Beijing  | 18751 |
| education | Huazhong University of Science and Technology | 947 |
| company  | Student | 757 |
| job      | Product Manager | 941 |


#### 3.1.2 Account Activities

The account activities of users are divided into three dimensions:

* Content Contribution: including *_answer, question, article_*;
* Social connection: including *_following, followers, favorite, topic, columns_*;
* Popularity and recognition: including *_agree, thanked_*.

Every variable, expect _following_, has extremely long tails.

Reference:
Richardson, J., & Swan, K. (2003). Examining social presence in online courses in relation to students' perceived learning and satisfaction.


### 3.2 Correlation Analysis

Here is the correlation matrix figure of variables involved in this study. In general, variables are uncorrelated with each other, however, some of them are relevant:

* _thanked_ and _agree_ are highly correlated( $r = 0.9628$);
* _followers_ and _agree_, _followers_ and _thanked_ are moderately correlated ($r = 0.6382, 0.6576$);
* _sex_ and _answer_, _columns_ and _following_,  _columns_ and _topic_ are slightly correlated($r = 0.3173, 0.3848, 0.3639$).

![Figure 3.1](C:\Users\liaoa\Desktop\corr.png "Figure 3.1")

### 3.3 Things to do

Now I am working on adding labels to the training and validation set. A few things to expect:
* Comparing expert users and non-expert in three account activities dimensions
* K - Means clustering
* Random Forest Classifiers
