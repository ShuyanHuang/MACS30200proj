{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Set your random seed to 1234\n",
    "    2. Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/Anaconda3-5.0.1-el7-x86_64/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(1234)\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "train_images, valid_images, train_labels, valid_labels = \\\n",
    "    train_test_split(train_images, train_labels, test_size = 0.16666, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.Implement a series of neural network models\n",
    "     - Note: Using 512 as hidden units for hidden layers lead to really bad results, so I choose 128 instead for every following model.\n",
    "\n",
    "        i.Initial test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 14.1055 - acc: 0.1028 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 14.4799 - acc: 0.1016 - val_loss: 14.4273 - val_acc: 0.1049\n"
     ]
    }
   ],
   "source": [
    "network_org = models.Sequential()\n",
    "network_org.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network_org.add(layers.Dense(512, activation='relu'))\n",
    "network_org.add(layers.Dense(512, activation='relu'))\n",
    "network_org.add(layers.Dense(512, activation='relu'))\n",
    "network_org.add(layers.Dense(10, activation='softmax'))\n",
    "network_org.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_org = network_org.fit(train_images, train_labels,validation_data=(valid_images,valid_labels), epochs=200, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,195,018\n",
      "Trainable params: 1,195,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network_org.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "val_acc = result_org.history['val_acc']\n",
    "val_loss = result_org.history['val_loss']\n",
    "plt.plot(val_acc)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['val_acc', 'val_loss'])\n",
    "plt.title('The validation set accuracy and loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.4353 - acc: 0.8742 - val_loss: 0.2797 - val_acc: 0.9176\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.2155 - acc: 0.9382 - val_loss: 0.2386 - val_acc: 0.9312\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.1564 - acc: 0.9551 - val_loss: 0.1431 - val_acc: 0.9570\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.1240 - acc: 0.9635 - val_loss: 0.1441 - val_acc: 0.9542\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0996 - acc: 0.9713 - val_loss: 0.1295 - val_acc: 0.9625\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0838 - acc: 0.9759 - val_loss: 0.0955 - val_acc: 0.9707\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0694 - acc: 0.9792 - val_loss: 0.1055 - val_acc: 0.9650\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0600 - acc: 0.9822 - val_loss: 0.0894 - val_acc: 0.9716\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0520 - acc: 0.9846 - val_loss: 0.0841 - val_acc: 0.9727\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0445 - acc: 0.9873 - val_loss: 0.0842 - val_acc: 0.9741\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0399 - acc: 0.9880 - val_loss: 0.0916 - val_acc: 0.9716\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0347 - acc: 0.9897 - val_loss: 0.0845 - val_acc: 0.9737\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0304 - acc: 0.9912 - val_loss: 0.0765 - val_acc: 0.9752\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0258 - acc: 0.9929 - val_loss: 0.0705 - val_acc: 0.9793\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0242 - acc: 0.9931 - val_loss: 0.0725 - val_acc: 0.9772\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0224 - acc: 0.9936 - val_loss: 0.0755 - val_acc: 0.9773\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0185 - acc: 0.9950 - val_loss: 0.0687 - val_acc: 0.9789\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0169 - acc: 0.9954 - val_loss: 0.1039 - val_acc: 0.9697\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0145 - acc: 0.9961 - val_loss: 0.0740 - val_acc: 0.9786\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0144 - acc: 0.9960 - val_loss: 0.0885 - val_acc: 0.9747\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0130 - acc: 0.9964 - val_loss: 0.0726 - val_acc: 0.9785\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0109 - acc: 0.9972 - val_loss: 0.0735 - val_acc: 0.9791\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0100 - acc: 0.9975 - val_loss: 0.0739 - val_acc: 0.9782\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0096 - acc: 0.9975 - val_loss: 0.0963 - val_acc: 0.9756\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0088 - acc: 0.9975 - val_loss: 0.0967 - val_acc: 0.9748\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0068 - acc: 0.9984 - val_loss: 0.0930 - val_acc: 0.9737\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0070 - acc: 0.9983 - val_loss: 0.0772 - val_acc: 0.9790\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0843 - val_acc: 0.9788\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0059 - acc: 0.9986 - val_loss: 0.0772 - val_acc: 0.9797\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0051 - acc: 0.9988 - val_loss: 0.0763 - val_acc: 0.9797\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0806 - val_acc: 0.9795\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.1024 - val_acc: 0.9736\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0817 - val_acc: 0.9798\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.0806 - val_acc: 0.9796\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.0781 - val_acc: 0.9816\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0044 - acc: 0.9988 - val_loss: 0.0789 - val_acc: 0.9807\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0820 - val_acc: 0.9799\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0944 - val_acc: 0.9780\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0804 - val_acc: 0.9807\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0799 - val_acc: 0.9801\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.1356 - val_acc: 0.9724\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.1060 - val_acc: 0.9770\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.1223 - val_acc: 0.9712\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0844 - val_acc: 0.9806\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.1050 - val_acc: 0.9763\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0868 - val_acc: 0.9812\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.1030 - val_acc: 0.9782\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.1351 - val_acc: 0.9723\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0867 - val_acc: 0.9820\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0937 - val_acc: 0.9795\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0899 - val_acc: 0.9808\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0022 - acc: 0.9992 - val_loss: 0.0910 - val_acc: 0.9810\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.1305 - val_acc: 0.9733\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0891 - val_acc: 0.9816\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0910 - val_acc: 0.9809\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.1093 - val_acc: 0.9778\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0913 - val_acc: 0.9815\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0925 - val_acc: 0.9821\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0027 - acc: 0.9994 - val_loss: 0.0963 - val_acc: 0.9813\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0950 - val_acc: 0.9808\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0952 - val_acc: 0.9817\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0933 - val_acc: 0.9817\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0928 - val_acc: 0.9818\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0949 - val_acc: 0.9816\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0943 - val_acc: 0.9818\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0945 - val_acc: 0.9820\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.1106 - val_acc: 0.9798\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0984 - val_acc: 0.9809\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 8.3784e-04 - acc: 0.9997 - val_loss: 0.0994 - val_acc: 0.9816\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.1063 - val_acc: 0.9806\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0995 - val_acc: 0.9815\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.1159 - val_acc: 0.9789\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.1018 - val_acc: 0.9813\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.1048 - val_acc: 0.9810\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 7.6716e-04 - acc: 0.9998 - val_loss: 0.1029 - val_acc: 0.9811\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0998 - val_acc: 0.9821\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.1050 - val_acc: 0.9813\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 8.3481e-04 - acc: 0.9998 - val_loss: 0.1025 - val_acc: 0.9819\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.1411 - val_acc: 0.9754\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 6.7228e-04 - acc: 0.9999 - val_loss: 0.1030 - val_acc: 0.9818\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 7.4324e-04 - acc: 0.9998 - val_loss: 0.1078 - val_acc: 0.9810\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 8.2887e-04 - acc: 0.9998 - val_loss: 0.1081 - val_acc: 0.9822\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.1207 - val_acc: 0.9793\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.1148 - val_acc: 0.9798\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.1106 - val_acc: 0.9807\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 7.7704e-04 - acc: 0.9998 - val_loss: 0.1077 - val_acc: 0.9817\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 9.0350e-04 - acc: 0.9998 - val_loss: 0.1053 - val_acc: 0.9819\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.1148 - val_acc: 0.9791\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.1099 - val_acc: 0.9812\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.1111 - val_acc: 0.9819\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 6.2579e-04 - acc: 0.9997 - val_loss: 0.1111 - val_acc: 0.9810\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 3.8878e-04 - acc: 0.9999 - val_loss: 0.1080 - val_acc: 0.9822\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.1129 - val_acc: 0.9803\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 9.7042e-04 - acc: 0.9998 - val_loss: 0.1081 - val_acc: 0.9808\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.2272e-04 - acc: 0.9998 - val_loss: 0.1085 - val_acc: 0.9810\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 8.6722e-04 - acc: 0.9998 - val_loss: 0.1115 - val_acc: 0.9813\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.1213 - val_acc: 0.9795\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.1132 - val_acc: 0.9812\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.1187 - val_acc: 0.9802\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.3294e-04 - acc: 0.9998 - val_loss: 0.1156 - val_acc: 0.9812\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.7210e-04 - acc: 1.0000 - val_loss: 0.1150 - val_acc: 0.9804\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.1174 - val_acc: 0.9799\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 5.2528e-04 - acc: 0.9998 - val_loss: 0.1182 - val_acc: 0.9808\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 6.4102e-04 - acc: 0.9999 - val_loss: 0.1155 - val_acc: 0.9807\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 7.7320e-04 - acc: 0.9998 - val_loss: 0.1152 - val_acc: 0.9808\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 3.8577e-04 - acc: 0.9999 - val_loss: 0.2380 - val_acc: 0.9651\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 8.9466e-04 - acc: 0.9998 - val_loss: 0.1157 - val_acc: 0.9816\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 9.9423e-04 - acc: 0.9997 - val_loss: 0.1393 - val_acc: 0.9777\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.1435 - val_acc: 0.9787\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.1174 - val_acc: 0.9808\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.1104e-04 - acc: 0.9999 - val_loss: 0.1402 - val_acc: 0.9766\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 8.1418e-04 - acc: 0.9998 - val_loss: 0.1201 - val_acc: 0.9807\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 7.8995e-04 - acc: 0.9997 - val_loss: 0.1170 - val_acc: 0.9827\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.1193 - val_acc: 0.9817\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 8.6536e-04 - acc: 0.9998 - val_loss: 0.1148 - val_acc: 0.9813\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.1330 - val_acc: 0.9791\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 54us/step - loss: 7.9601e-04 - acc: 0.9998 - val_loss: 0.1191 - val_acc: 0.9811\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 4.9316e-04 - acc: 0.9998 - val_loss: 0.1215 - val_acc: 0.9810\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 7.6174e-04 - acc: 0.9998 - val_loss: 0.1209 - val_acc: 0.9812\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.1209 - val_acc: 0.9812\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.1481e-04 - acc: 0.9999 - val_loss: 0.1167 - val_acc: 0.9821\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 7.9998e-04 - acc: 0.9998 - val_loss: 0.1179 - val_acc: 0.9817\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.4288e-04 - acc: 0.9999 - val_loss: 0.1208 - val_acc: 0.9816\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 9.4155e-04 - acc: 0.9998 - val_loss: 0.1223 - val_acc: 0.9812\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 2.7683e-04 - acc: 0.9999 - val_loss: 0.1162 - val_acc: 0.9814\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.1248 - val_acc: 0.9811\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 7.7718e-04 - acc: 0.9997 - val_loss: 0.1267 - val_acc: 0.9809\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.1249 - val_acc: 0.9811\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 4.2434e-04 - acc: 0.9999 - val_loss: 0.1415 - val_acc: 0.9782\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.1432 - val_acc: 0.9787\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 8.1303e-05 - acc: 0.9999 - val_loss: 0.1243 - val_acc: 0.9811\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.1221 - val_acc: 0.9812\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 7.4784e-04 - acc: 0.9999 - val_loss: 0.1299 - val_acc: 0.9804\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 6.2888e-04 - acc: 0.9998 - val_loss: 0.1450 - val_acc: 0.9783\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 8.5928e-04 - acc: 0.9998 - val_loss: 0.1217 - val_acc: 0.9809\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0004e-04 - acc: 0.9999 - val_loss: 0.1262 - val_acc: 0.9809\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 8.8518e-04 - acc: 0.9999 - val_loss: 0.1223 - val_acc: 0.9815\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.1361 - val_acc: 0.9793\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 9.8995e-06 - acc: 1.0000 - val_loss: 0.1247 - val_acc: 0.9817\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 5.4065e-04 - acc: 0.9999 - val_loss: 0.1245 - val_acc: 0.9810\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.2297 - val_acc: 0.9688\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 8.4846e-04 - acc: 0.9997 - val_loss: 0.1263 - val_acc: 0.9817\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 6.3719e-04 - acc: 0.9998 - val_loss: 0.1326 - val_acc: 0.9810\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.8682e-04 - acc: 0.9999 - val_loss: 0.1304 - val_acc: 0.9823\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 5.6666e-04 - acc: 0.9999 - val_loss: 0.1322 - val_acc: 0.9815\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.1279 - val_acc: 0.9810\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 9.2825e-04 - acc: 0.9998 - val_loss: 0.1267 - val_acc: 0.9825\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.1526 - val_acc: 0.9793\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 3.6270e-04 - acc: 0.9999 - val_loss: 0.1324 - val_acc: 0.9815\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 9.1517e-04 - acc: 0.9999 - val_loss: 0.1300 - val_acc: 0.9818\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.9699e-04 - acc: 0.9998 - val_loss: 0.1341 - val_acc: 0.9810\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.1091e-04 - acc: 0.9999 - val_loss: 0.1306 - val_acc: 0.9820\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 8.5830e-04 - acc: 0.9997 - val_loss: 0.1401 - val_acc: 0.9804\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 8.7360e-04 - acc: 0.9998 - val_loss: 0.1326 - val_acc: 0.9812\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.1357 - val_acc: 0.9811\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.1468e-04 - acc: 0.9999 - val_loss: 0.1390 - val_acc: 0.9801\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.1304 - val_acc: 0.9821\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 6.8654e-04 - acc: 0.9998 - val_loss: 0.1331 - val_acc: 0.9816\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 6.5665e-04 - acc: 0.9998 - val_loss: 0.1358 - val_acc: 0.9811\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 8.2584e-04 - acc: 0.9998 - val_loss: 0.1399 - val_acc: 0.9800\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.3022e-04 - acc: 0.9999 - val_loss: 0.1370 - val_acc: 0.9811\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 8.4042e-04 - acc: 0.9998 - val_loss: 0.1456 - val_acc: 0.9802\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.1577 - val_acc: 0.9789\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 7.3483e-04 - acc: 0.9998 - val_loss: 0.1310 - val_acc: 0.9820\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 7.3180e-04 - acc: 0.9998 - val_loss: 0.1422 - val_acc: 0.9808\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 3.3946e-04 - acc: 0.9999 - val_loss: 0.1425 - val_acc: 0.9805\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.8264e-04 - acc: 0.9999 - val_loss: 0.1445 - val_acc: 0.9805\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 6.1199e-04 - acc: 0.9999 - val_loss: 0.1392 - val_acc: 0.9812\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 7.3638e-04 - acc: 0.9998 - val_loss: 0.1424 - val_acc: 0.9812\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 8.4109e-04 - acc: 0.9998 - val_loss: 0.1367 - val_acc: 0.9817\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.9614e-06 - acc: 1.0000 - val_loss: 0.1335 - val_acc: 0.9815\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 4.6705e-04 - acc: 0.9998 - val_loss: 0.1325 - val_acc: 0.9821\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.8773e-04 - acc: 0.9999 - val_loss: 0.1362 - val_acc: 0.9812\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 53us/step - loss: 4.5692e-04 - acc: 0.9999 - val_loss: 0.1371 - val_acc: 0.9820\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 6.2407e-04 - acc: 0.9998 - val_loss: 0.1697 - val_acc: 0.9783\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 6.1413e-05 - acc: 1.0000 - val_loss: 0.1317 - val_acc: 0.9825\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.3160e-04 - acc: 1.0000 - val_loss: 0.1304 - val_acc: 0.9816\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 6.6140e-04 - acc: 0.9998 - val_loss: 0.1318 - val_acc: 0.9812\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.1399 - val_acc: 0.9823\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.5252e-04 - acc: 0.9999 - val_loss: 0.2172 - val_acc: 0.9717\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.6923e-04 - acc: 0.9999 - val_loss: 0.1334 - val_acc: 0.9813\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.1371 - val_acc: 0.9813\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1529 - val_acc: 0.9802\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 7.3168e-06 - acc: 1.0000 - val_loss: 0.1353 - val_acc: 0.9819\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 5.2369e-04 - acc: 0.9999 - val_loss: 0.1380 - val_acc: 0.9809\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 7.3560e-04 - acc: 0.9997 - val_loss: 0.1462 - val_acc: 0.9803\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 6.6600e-04 - acc: 0.9999 - val_loss: 0.1496 - val_acc: 0.9802\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.1408 - val_acc: 0.9815\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 5.2809e-04 - acc: 0.9999 - val_loss: 0.1978 - val_acc: 0.9756\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.9933e-04 - acc: 1.0000 - val_loss: 0.1395 - val_acc: 0.9813\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0014 - acc: 0.9999 - val_loss: 0.1369 - val_acc: 0.9813\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.1392 - val_acc: 0.9810\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 4.6055e-04 - acc: 0.9999 - val_loss: 0.1401 - val_acc: 0.9810\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 7.6946e-04 - acc: 0.9999 - val_loss: 0.1715 - val_acc: 0.9774\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 9.7566e-05 - acc: 1.0000 - val_loss: 0.1354 - val_acc: 0.9817\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 6.3264e-04 - acc: 0.9999 - val_loss: 0.1457 - val_acc: 0.9809\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.1614 - val_acc: 0.9800\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 4.8388e-06 - acc: 1.0000 - val_loss: 0.1419 - val_acc: 0.9808\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 4.2135e-04 - acc: 0.9999 - val_loss: 0.1419 - val_acc: 0.9804\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 6.0913e-04 - acc: 0.9999 - val_loss: 0.1479 - val_acc: 0.9801\n"
     ]
    }
   ],
   "source": [
    "network_org = models.Sequential()\n",
    "network_org.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network_org.add(layers.Dense(10, activation='softmax'))\n",
    "network_org.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_org = network_org.fit(train_images, train_labels,validation_data=(valid_images,valid_labels), epochs=200, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network_org.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "val_acc = result_org.history['val_acc']\n",
    "val_loss = result_org.history['val_loss']\n",
    "plt.plot(val_acc)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['val_acc', 'val_loss'])\n",
    "plt.title('The validation set accuracy and loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the epoch where the model's performance degrades based on the validation set:\n",
    "\n",
    "#From Epoch 12, the model starts to perform worse and worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        ii. Implement dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.3082 - acc: 0.5415 - val_loss: 0.4453 - val_acc: 0.8821\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.6373 - acc: 0.8063 - val_loss: 0.3061 - val_acc: 0.9123\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.4704 - acc: 0.8683 - val_loss: 0.2482 - val_acc: 0.9303\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.3833 - acc: 0.8962 - val_loss: 0.2073 - val_acc: 0.9422\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.3335 - acc: 0.9134 - val_loss: 0.1833 - val_acc: 0.9492\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.3040 - acc: 0.9208 - val_loss: 0.1646 - val_acc: 0.9524\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.2752 - acc: 0.9299 - val_loss: 0.1650 - val_acc: 0.9507\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.2541 - acc: 0.9354 - val_loss: 0.1420 - val_acc: 0.9582\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.2417 - acc: 0.9389 - val_loss: 0.1454 - val_acc: 0.9588\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.2260 - acc: 0.9425 - val_loss: 0.1295 - val_acc: 0.9628\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.2118 - acc: 0.9461 - val_loss: 0.1196 - val_acc: 0.9656\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1998 - acc: 0.9482 - val_loss: 0.1234 - val_acc: 0.9655\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1989 - acc: 0.9513 - val_loss: 0.1192 - val_acc: 0.9664\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1866 - acc: 0.9537 - val_loss: 0.1069 - val_acc: 0.9695\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1804 - acc: 0.9545 - val_loss: 0.1193 - val_acc: 0.9688\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1771 - acc: 0.9547 - val_loss: 0.1060 - val_acc: 0.9697\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1708 - acc: 0.9572 - val_loss: 0.0993 - val_acc: 0.9714\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1694 - acc: 0.9575 - val_loss: 0.0965 - val_acc: 0.9717\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.1613 - acc: 0.9602 - val_loss: 0.0979 - val_acc: 0.9737\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.1614 - acc: 0.9602 - val_loss: 0.1020 - val_acc: 0.9726\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1558 - acc: 0.9627 - val_loss: 0.0957 - val_acc: 0.9730\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1530 - acc: 0.9628 - val_loss: 0.0948 - val_acc: 0.9738\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.1512 - acc: 0.9625 - val_loss: 0.0941 - val_acc: 0.9737\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1478 - acc: 0.9652 - val_loss: 0.0863 - val_acc: 0.9762\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.1440 - acc: 0.9643 - val_loss: 0.0882 - val_acc: 0.9748\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.1413 - acc: 0.9649 - val_loss: 0.0904 - val_acc: 0.9763\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1423 - acc: 0.9653 - val_loss: 0.0960 - val_acc: 0.9744\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.1458 - acc: 0.9651 - val_loss: 0.0885 - val_acc: 0.9752\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1405 - acc: 0.9666 - val_loss: 0.0897 - val_acc: 0.9759\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1394 - acc: 0.9662 - val_loss: 0.0928 - val_acc: 0.9735\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.1377 - acc: 0.9667 - val_loss: 0.0955 - val_acc: 0.9749\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1381 - acc: 0.9674 - val_loss: 0.0953 - val_acc: 0.9759\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1346 - acc: 0.9676 - val_loss: 0.0864 - val_acc: 0.9769\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1373 - acc: 0.9678 - val_loss: 0.0917 - val_acc: 0.9763\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1413 - acc: 0.9670 - val_loss: 0.0922 - val_acc: 0.9765\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1457 - acc: 0.9672 - val_loss: 0.0887 - val_acc: 0.9776\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1389 - acc: 0.9675 - val_loss: 0.0899 - val_acc: 0.9758\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.1400 - acc: 0.9677 - val_loss: 0.0955 - val_acc: 0.9754\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1420 - acc: 0.9665 - val_loss: 0.0985 - val_acc: 0.9762\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1491 - acc: 0.9663 - val_loss: 0.1027 - val_acc: 0.9773\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1538 - acc: 0.9661 - val_loss: 0.1052 - val_acc: 0.9743\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1641 - acc: 0.9639 - val_loss: 0.1165 - val_acc: 0.9752\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1883 - acc: 0.9615 - val_loss: 0.1145 - val_acc: 0.9759\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.2165 - acc: 0.9598 - val_loss: 0.1366 - val_acc: 0.9764\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.2792 - acc: 0.9543 - val_loss: 0.1983 - val_acc: 0.9760\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.4058 - acc: 0.9514 - val_loss: 0.2894 - val_acc: 0.9708\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.5690 - acc: 0.9467 - val_loss: 0.3838 - val_acc: 0.9692\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.7048 - acc: 0.9437 - val_loss: 0.4616 - val_acc: 0.9668\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.8791 - acc: 0.9363 - val_loss: 0.4823 - val_acc: 0.9670\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.9946 - acc: 0.9319 - val_loss: 0.5549 - val_acc: 0.9639\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.0967 - acc: 0.9267 - val_loss: 0.5574 - val_acc: 0.9630\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3201 - acc: 0.9142 - val_loss: 0.6144 - val_acc: 0.9607\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.4041 - acc: 0.9096 - val_loss: 0.7534 - val_acc: 0.9518\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.5459 - acc: 0.9011 - val_loss: 0.7175 - val_acc: 0.9543\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6687 - acc: 0.8936 - val_loss: 0.6692 - val_acc: 0.9577\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.8459 - acc: 0.8828 - val_loss: 0.6716 - val_acc: 0.9578\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 2.0590 - acc: 0.8701 - val_loss: 0.8549 - val_acc: 0.9464\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 2.2522 - acc: 0.8584 - val_loss: 0.8765 - val_acc: 0.9450\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 2.3735 - acc: 0.8511 - val_loss: 0.9878 - val_acc: 0.9381\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 2.5190 - acc: 0.8420 - val_loss: 0.9646 - val_acc: 0.9399\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 2.5861 - acc: 0.8378 - val_loss: 0.9308 - val_acc: 0.9419\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 2.7021 - acc: 0.8308 - val_loss: 1.2298 - val_acc: 0.9227\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 2.9702 - acc: 0.8143 - val_loss: 1.1136 - val_acc: 0.9302\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 3.2525 - acc: 0.7969 - val_loss: 1.2482 - val_acc: 0.9221\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 3.5947 - acc: 0.7759 - val_loss: 2.0366 - val_acc: 0.8727\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 3.8345 - acc: 0.7610 - val_loss: 1.5371 - val_acc: 0.9041\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 4.1924 - acc: 0.7388 - val_loss: 1.7513 - val_acc: 0.8906\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 4.4166 - acc: 0.7252 - val_loss: 1.6193 - val_acc: 0.8989\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 4.8955 - acc: 0.6953 - val_loss: 1.7550 - val_acc: 0.8908\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 5.4555 - acc: 0.6607 - val_loss: 1.4629 - val_acc: 0.9088\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 5.5579 - acc: 0.6545 - val_loss: 3.0881 - val_acc: 0.8080\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 6.1327 - acc: 0.6189 - val_loss: 2.5180 - val_acc: 0.8434\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 6.3792 - acc: 0.6037 - val_loss: 3.0049 - val_acc: 0.8130\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 6.7485 - acc: 0.5807 - val_loss: 3.8477 - val_acc: 0.7610\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 7.1922 - acc: 0.5533 - val_loss: 3.0835 - val_acc: 0.8083\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 6.9217 - acc: 0.5701 - val_loss: 3.9213 - val_acc: 0.7560\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 7.3553 - acc: 0.5432 - val_loss: 2.2427 - val_acc: 0.8602\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 7.9247 - acc: 0.5080 - val_loss: 5.0377 - val_acc: 0.6871\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 8.6446 - acc: 0.4634 - val_loss: 5.9316 - val_acc: 0.6316\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 9.1218 - acc: 0.4338 - val_loss: 5.9332 - val_acc: 0.6314\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 9.2120 - acc: 0.4283 - val_loss: 9.2199 - val_acc: 0.4276\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 9.9300 - acc: 0.3836 - val_loss: 7.0807 - val_acc: 0.5607\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 9.2492 - acc: 0.4259 - val_loss: 5.3674 - val_acc: 0.6668\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 9.3146 - acc: 0.4219 - val_loss: 4.1418 - val_acc: 0.7429\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 9.6518 - acc: 0.4009 - val_loss: 5.7263 - val_acc: 0.6447\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 9.4392 - acc: 0.4143 - val_loss: 5.7150 - val_acc: 0.6452\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 9.8608 - acc: 0.3881 - val_loss: 8.8923 - val_acc: 0.4482\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 10.2334 - acc: 0.3650 - val_loss: 7.6278 - val_acc: 0.5265\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 10.2006 - acc: 0.3670 - val_loss: 8.8898 - val_acc: 0.4483\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 10.6143 - acc: 0.3413 - val_loss: 7.4598 - val_acc: 0.5371\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 10.3260 - acc: 0.3592 - val_loss: 7.0146 - val_acc: 0.5645\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 10.4828 - acc: 0.3495 - val_loss: 8.8405 - val_acc: 0.4512\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 10.9147 - acc: 0.3228 - val_loss: 8.3654 - val_acc: 0.4809\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 10.9600 - acc: 0.3199 - val_loss: 8.9211 - val_acc: 0.4464\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 10.8707 - acc: 0.3255 - val_loss: 10.2532 - val_acc: 0.3636\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 11.0749 - acc: 0.3129 - val_loss: 8.9700 - val_acc: 0.4434\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 10.9847 - acc: 0.3184 - val_loss: 9.7238 - val_acc: 0.3965\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 11.3242 - acc: 0.2973 - val_loss: 10.2212 - val_acc: 0.3657\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 11.1545 - acc: 0.3079 - val_loss: 9.1453 - val_acc: 0.4326\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 11.0564 - acc: 0.3139 - val_loss: 8.0897 - val_acc: 0.4981\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 11.6291 - acc: 0.2784 - val_loss: 8.4692 - val_acc: 0.4744\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 11.3963 - acc: 0.2929 - val_loss: 9.2801 - val_acc: 0.4242\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 11.1933 - acc: 0.3055 - val_loss: 6.9555 - val_acc: 0.5684\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 11.1051 - acc: 0.3109 - val_loss: 9.1358 - val_acc: 0.4332\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 11.5074 - acc: 0.2860 - val_loss: 11.4842 - val_acc: 0.2873\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 12.6711 - acc: 0.2138 - val_loss: 12.0521 - val_acc: 0.2522\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 11.8917 - acc: 0.2622 - val_loss: 11.4781 - val_acc: 0.2878\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 11.5333 - acc: 0.2844 - val_loss: 9.2121 - val_acc: 0.4283\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 11.8280 - acc: 0.2661 - val_loss: 10.7921 - val_acc: 0.3304\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 12.0678 - acc: 0.2512 - val_loss: 10.3530 - val_acc: 0.3576\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 11.7249 - acc: 0.2724 - val_loss: 9.9759 - val_acc: 0.3810\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 11.9883 - acc: 0.2561 - val_loss: 9.6335 - val_acc: 0.4022\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 12.3710 - acc: 0.2324 - val_loss: 12.7822 - val_acc: 0.2069\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 12.5126 - acc: 0.2236 - val_loss: 10.1264 - val_acc: 0.3717\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 12.1917 - acc: 0.2436 - val_loss: 10.7524 - val_acc: 0.3329\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 12.4532 - acc: 0.2273 - val_loss: 12.4670 - val_acc: 0.2265\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 4s 81us/step - loss: 12.7716 - acc: 0.2076 - val_loss: 12.6293 - val_acc: 0.2164\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.0252 - acc: 0.1919 - val_loss: 14.2081 - val_acc: 0.1185\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 12.7510 - acc: 0.2089 - val_loss: 12.2988 - val_acc: 0.2368\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 12.2590 - acc: 0.2394 - val_loss: 11.5486 - val_acc: 0.2834\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 12.4613 - acc: 0.2268 - val_loss: 10.5106 - val_acc: 0.3479\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 12.3616 - acc: 0.2330 - val_loss: 13.3490 - val_acc: 0.1718\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 12.8261 - acc: 0.2042 - val_loss: 11.4505 - val_acc: 0.2893\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 12.5051 - acc: 0.2241 - val_loss: 10.1576 - val_acc: 0.3698\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 12.3749 - acc: 0.2322 - val_loss: 10.1719 - val_acc: 0.3688\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 12.5691 - acc: 0.2202 - val_loss: 11.3548 - val_acc: 0.2955\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 12.8906 - acc: 0.2002 - val_loss: 12.9938 - val_acc: 0.1938\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 13.1645 - acc: 0.1832 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.6707 - acc: 0.1518 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.5234 - acc: 0.1610 - val_loss: 14.0695 - val_acc: 0.1271\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.2391 - acc: 0.1786 - val_loss: 13.1701 - val_acc: 0.1829\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 12.7675 - acc: 0.2078 - val_loss: 11.0797 - val_acc: 0.3125\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 12.6099 - acc: 0.2176 - val_loss: 11.7565 - val_acc: 0.2706\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 12.8521 - acc: 0.2026 - val_loss: 12.2759 - val_acc: 0.2383\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 12.6917 - acc: 0.2126 - val_loss: 11.4165 - val_acc: 0.2917\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 12.9335 - acc: 0.1976 - val_loss: 14.1598 - val_acc: 0.1215\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.1825 - acc: 0.1821 - val_loss: 14.0953 - val_acc: 0.1255\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.3404 - acc: 0.1723 - val_loss: 14.2210 - val_acc: 0.1177\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 13.1949 - acc: 0.1813 - val_loss: 13.4029 - val_acc: 0.1684\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 12.9336 - acc: 0.1976 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 12.9055 - acc: 0.1993 - val_loss: 13.5956 - val_acc: 0.1565\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.0618 - acc: 0.1896 - val_loss: 11.8130 - val_acc: 0.2671\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 12.9012 - acc: 0.1996 - val_loss: 12.6737 - val_acc: 0.2137\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.0228 - acc: 0.1920 - val_loss: 11.5712 - val_acc: 0.2821\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.0850 - acc: 0.1882 - val_loss: 12.3223 - val_acc: 0.2355\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 13.0850 - acc: 0.1882 - val_loss: 12.6140 - val_acc: 0.2174\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 13.0844 - acc: 0.1882 - val_loss: 13.7004 - val_acc: 0.1500\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 13.0845 - acc: 0.1882 - val_loss: 13.2339 - val_acc: 0.1789\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 13.5938 - acc: 0.1566 - val_loss: 14.4757 - val_acc: 0.1019\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.6765 - acc: 0.1515 - val_loss: 14.4757 - val_acc: 0.1019\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.7004 - acc: 0.1500 - val_loss: 14.4741 - val_acc: 0.1020\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.7357 - acc: 0.1478 - val_loss: 14.4741 - val_acc: 0.1020\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.0750 - acc: 0.1888 - val_loss: 13.1274 - val_acc: 0.1855\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.1437 - acc: 0.1845 - val_loss: 14.4273 - val_acc: 0.1049\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 13.4912 - acc: 0.1630 - val_loss: 13.7771 - val_acc: 0.1451\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 13.2512 - acc: 0.1779 - val_loss: 12.5915 - val_acc: 0.2188\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.1895 - acc: 0.1817 - val_loss: 11.1038 - val_acc: 0.3111\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.1325 - acc: 0.1852 - val_loss: 12.6350 - val_acc: 0.2161\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.3183 - acc: 0.1737 - val_loss: 13.7778 - val_acc: 0.1452\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.4437 - acc: 0.1659 - val_loss: 12.7704 - val_acc: 0.2077\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 13.4636 - acc: 0.1647 - val_loss: 12.7043 - val_acc: 0.2118\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 13.5436 - acc: 0.1597 - val_loss: 13.0186 - val_acc: 0.1923\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 13.8542 - acc: 0.1405 - val_loss: 14.3467 - val_acc: 0.1099\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 14.1669 - acc: 0.1211 - val_loss: 14.4773 - val_acc: 0.1018\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 14.0721 - acc: 0.1269 - val_loss: 14.4741 - val_acc: 0.1020\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.5976 - acc: 0.1564 - val_loss: 12.6672 - val_acc: 0.2141\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.5470 - acc: 0.1595 - val_loss: 12.7140 - val_acc: 0.2112\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.5956 - acc: 0.1565 - val_loss: 12.6640 - val_acc: 0.2143\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.4815 - acc: 0.1636 - val_loss: 12.6640 - val_acc: 0.2143\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 13.4564 - acc: 0.1651 - val_loss: 12.6656 - val_acc: 0.2142\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.5398 - acc: 0.1599 - val_loss: 13.8213 - val_acc: 0.1425\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.5346 - acc: 0.1603 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.8097 - acc: 0.1432 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.8258 - acc: 0.1422 - val_loss: 14.2355 - val_acc: 0.1168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.7316 - acc: 0.1481 - val_loss: 14.2339 - val_acc: 0.1169\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.7985 - acc: 0.1439 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.8712 - acc: 0.1394 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.9997 - acc: 0.1314 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 14.0321 - acc: 0.1294 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.8948 - acc: 0.1379 - val_loss: 13.0541 - val_acc: 0.1901\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 13.6851 - acc: 0.1509 - val_loss: 12.8639 - val_acc: 0.2019\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 13.6979 - acc: 0.1501 - val_loss: 13.9679 - val_acc: 0.1334\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.8144 - acc: 0.1429 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.7419 - acc: 0.1474 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.8226 - acc: 0.1424 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.7852 - acc: 0.1447 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.9122 - acc: 0.1369 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 14.0237 - acc: 0.1299 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 14.1739 - acc: 0.1206 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 14.1814 - acc: 0.1202 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 14.1794 - acc: 0.1203 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 14.1778 - acc: 0.1204 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 14.1797 - acc: 0.1203 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 14.0345 - acc: 0.1293 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.8854 - acc: 0.1385 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.8425 - acc: 0.1412 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 13.6954 - acc: 0.1503 - val_loss: 12.9672 - val_acc: 0.1954\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.5079 - acc: 0.1619 - val_loss: 13.6385 - val_acc: 0.1538\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.5457 - acc: 0.1596 - val_loss: 12.6849 - val_acc: 0.2130\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 13.4773 - acc: 0.1638 - val_loss: 12.7107 - val_acc: 0.2114\n"
     ]
    }
   ],
   "source": [
    "network_dropout = models.Sequential()\n",
    "network_dropout.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network_dropout.add(layers.Dropout(0.5))\n",
    "network_dropout.add(layers.Dense(128, activation='relu'))\n",
    "network_dropout.add(layers.Dropout(0.5))\n",
    "network_dropout.add(layers.Dense(128, activation='relu'))\n",
    "network_dropout.add(layers.Dropout(0.5))\n",
    "network_dropout.add(layers.Dense(128, activation='relu'))\n",
    "network_dropout.add(layers.Dropout(0.5))\n",
    "network_dropout.add(layers.Dense(10, activation='softmax'))\n",
    "network_dropout.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_dropout = network_dropout.fit(train_images, train_labels,validation_data=(valid_images,valid_labels), epochs=200, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 501,898\n",
      "Trainable params: 501,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_acc = result_org.history['val_acc']\n",
    "val_loss = result_org.history['val_loss']\n",
    "val_acc_dropout = result_dropout.history['val_acc']\n",
    "val_loss_dropout = result_dropout.history['val_loss']\n",
    "plt.plot(val_acc)\n",
    "plt.plot(val_loss)\n",
    "plt.plot(val_acc_dropout)\n",
    "plt.plot(val_loss_dropout)\n",
    "plt.legend(['val_acc', 'val_loss', 'val_acc_dropout', 'val_loss_dropout'])\n",
    "plt.title('The validation set accuracy and loss of original model and dropout model over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this new model perform relative to the old model?\n",
    "\n",
    "This model perform much better compared with the old model in terms of val_loss and val_acc, especailly when epoch number is smaller than 75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        iii.Weight regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 10.6262 - acc: 0.5399 - val_loss: 11.9664 - val_acc: 0.4247\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 15.8846 - acc: 0.2743 - val_loss: 16.2500 - val_acc: 0.1910\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 16.1868 - acc: 0.1988 - val_loss: 15.5508 - val_acc: 0.2000\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 16.4884 - acc: 0.1160 - val_loss: 16.7651 - val_acc: 0.0975\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 16.2562 - acc: 0.1027 - val_loss: 16.2743 - val_acc: 0.1001\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 15.7613 - acc: 0.1158 - val_loss: 15.0178 - val_acc: 0.1518\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 15.0513 - acc: 0.1616 - val_loss: 14.6710 - val_acc: 0.1880\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 14.6850 - acc: 0.1778 - val_loss: 14.4191 - val_acc: 0.1912\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 14.3752 - acc: 0.1856 - val_loss: 14.4124 - val_acc: 0.1788\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 14.1459 - acc: 0.1948 - val_loss: 14.2260 - val_acc: 0.1922\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 14.0101 - acc: 0.1969 - val_loss: 14.1278 - val_acc: 0.1925\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 14.1177 - acc: 0.1824 - val_loss: 14.1313 - val_acc: 0.1909\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 14.2135 - acc: 0.1822 - val_loss: 14.2804 - val_acc: 0.1866\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.9986 - acc: 0.1955 - val_loss: 14.0526 - val_acc: 0.1923\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 14.0774 - acc: 0.1858 - val_loss: 14.2064 - val_acc: 0.1721\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 14.0103 - acc: 0.1877 - val_loss: 13.9820 - val_acc: 0.1924\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.9753 - acc: 0.1885 - val_loss: 13.9431 - val_acc: 0.1929\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.8896 - acc: 0.1926 - val_loss: 13.9085 - val_acc: 0.1936\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.8175 - acc: 0.1946 - val_loss: 13.9093 - val_acc: 0.1917\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.7579 - acc: 0.1945 - val_loss: 13.7796 - val_acc: 0.1937\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 13.7291 - acc: 0.1923 - val_loss: 14.8468 - val_acc: 0.0949\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6959 - acc: 0.1933 - val_loss: 13.7984 - val_acc: 0.1937\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.7546 - acc: 0.1944 - val_loss: 13.8621 - val_acc: 0.1869\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.7772 - acc: 0.1911 - val_loss: 13.7561 - val_acc: 0.1918\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6775 - acc: 0.1944 - val_loss: 13.6862 - val_acc: 0.1936\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6195 - acc: 0.1946 - val_loss: 13.6298 - val_acc: 0.1944\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5331 - acc: 0.1897 - val_loss: 13.6340 - val_acc: 0.1943\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6563 - acc: 0.1905 - val_loss: 14.1000 - val_acc: 0.1501\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6238 - acc: 0.1948 - val_loss: 13.6371 - val_acc: 0.1946\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5466 - acc: 0.1896 - val_loss: 13.1260 - val_acc: 0.1948\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 13.8341 - acc: 0.1821 - val_loss: 13.7579 - val_acc: 0.1901\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.7967 - acc: 0.1826 - val_loss: 13.9497 - val_acc: 0.1755\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.7355 - acc: 0.1895 - val_loss: 14.3843 - val_acc: 0.1298\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.7455 - acc: 0.1893 - val_loss: 13.9030 - val_acc: 0.1862\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 13.6860 - acc: 0.1934 - val_loss: 13.8417 - val_acc: 0.1882\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.2981 - acc: 0.2151 - val_loss: 13.8396 - val_acc: 0.1949\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6699 - acc: 0.2053 - val_loss: 14.0812 - val_acc: 0.1827\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.8048 - acc: 0.1963 - val_loss: 13.8181 - val_acc: 0.1932\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.7044 - acc: 0.1976 - val_loss: 13.7130 - val_acc: 0.1953\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6308 - acc: 0.1982 - val_loss: 13.6530 - val_acc: 0.1949\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.9398 - acc: 0.2234 - val_loss: 13.0086 - val_acc: 0.2203\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.7868 - acc: 0.2357 - val_loss: 12.6557 - val_acc: 0.2482\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 12.8328 - acc: 0.2404 - val_loss: 12.9523 - val_acc: 0.2317\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.9987 - acc: 0.2372 - val_loss: 12.9460 - val_acc: 0.2434\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 13.0379 - acc: 0.2414 - val_loss: 13.1863 - val_acc: 0.2322\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.0654 - acc: 0.2453 - val_loss: 12.9620 - val_acc: 0.2576\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.2220 - acc: 0.2407 - val_loss: 12.9989 - val_acc: 0.2560\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.0944 - acc: 0.2506 - val_loss: 13.0092 - val_acc: 0.2573\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.0974 - acc: 0.2515 - val_loss: 12.9951 - val_acc: 0.2591\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.0425 - acc: 0.2560 - val_loss: 13.2659 - val_acc: 0.2406\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.0255 - acc: 0.2569 - val_loss: 13.0064 - val_acc: 0.2599\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.9660 - acc: 0.2615 - val_loss: 12.9844 - val_acc: 0.2594\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.9631 - acc: 0.2614 - val_loss: 12.9167 - val_acc: 0.2645\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.9282 - acc: 0.2629 - val_loss: 13.1741 - val_acc: 0.2454\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.9094 - acc: 0.2631 - val_loss: 14.4046 - val_acc: 0.1719\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.8926 - acc: 0.2634 - val_loss: 12.8822 - val_acc: 0.2635\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.8276 - acc: 0.2666 - val_loss: 12.8169 - val_acc: 0.2662\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.8147 - acc: 0.2663 - val_loss: 12.9433 - val_acc: 0.2585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.7709 - acc: 0.2682 - val_loss: 12.9741 - val_acc: 0.2532\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.7597 - acc: 0.2676 - val_loss: 12.8172 - val_acc: 0.2627\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.7173 - acc: 0.2688 - val_loss: 12.7022 - val_acc: 0.2695\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.6803 - acc: 0.2699 - val_loss: 12.7287 - val_acc: 0.2664\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.6419 - acc: 0.2710 - val_loss: 12.7079 - val_acc: 0.2672\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.6178 - acc: 0.2716 - val_loss: 12.6505 - val_acc: 0.2694\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.5840 - acc: 0.2724 - val_loss: 12.6739 - val_acc: 0.2661\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.5510 - acc: 0.2730 - val_loss: 12.5470 - val_acc: 0.2731\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.5174 - acc: 0.2741 - val_loss: 12.5188 - val_acc: 0.2737\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.4974 - acc: 0.2742 - val_loss: 12.5009 - val_acc: 0.2733\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.4651 - acc: 0.2747 - val_loss: 12.4817 - val_acc: 0.2736\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.4296 - acc: 0.2759 - val_loss: 12.4880 - val_acc: 0.2710\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.4078 - acc: 0.2758 - val_loss: 12.4104 - val_acc: 0.2746\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.3655 - acc: 0.2766 - val_loss: 12.4640 - val_acc: 0.2702\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.3328 - acc: 0.2773 - val_loss: 12.3524 - val_acc: 0.2753\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.2948 - acc: 0.2779 - val_loss: 12.3198 - val_acc: 0.2756\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.2641 - acc: 0.2784 - val_loss: 12.2915 - val_acc: 0.2757\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.2306 - acc: 0.2789 - val_loss: 12.2660 - val_acc: 0.2756\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.2066 - acc: 0.2779 - val_loss: 12.2337 - val_acc: 0.2765\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.1716 - acc: 0.2790 - val_loss: 12.2773 - val_acc: 0.2698\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.1467 - acc: 0.2788 - val_loss: 12.1907 - val_acc: 0.2746\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.1087 - acc: 0.2789 - val_loss: 12.1350 - val_acc: 0.2777\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.0777 - acc: 0.2784 - val_loss: 12.0941 - val_acc: 0.2783\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.0335 - acc: 0.2786 - val_loss: 12.0592 - val_acc: 0.2766\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.9883 - acc: 0.2772 - val_loss: 12.0079 - val_acc: 0.2767\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.9494 - acc: 0.2770 - val_loss: 12.1464 - val_acc: 0.2304\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.9175 - acc: 0.2768 - val_loss: 12.0786 - val_acc: 0.2544\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.9036 - acc: 0.2747 - val_loss: 11.9558 - val_acc: 0.2706\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.8811 - acc: 0.2765 - val_loss: 11.9194 - val_acc: 0.2765\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.8696 - acc: 0.2754 - val_loss: 11.9078 - val_acc: 0.2756\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.8616 - acc: 0.2747 - val_loss: 11.9017 - val_acc: 0.2786\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.8477 - acc: 0.2747 - val_loss: 11.9303 - val_acc: 0.2683\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.8386 - acc: 0.2749 - val_loss: 12.0138 - val_acc: 0.2380\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.8363 - acc: 0.2748 - val_loss: 11.9428 - val_acc: 0.2578\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.8289 - acc: 0.2751 - val_loss: 11.8696 - val_acc: 0.2768\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.8180 - acc: 0.2769 - val_loss: 11.9357 - val_acc: 0.2469\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.8179 - acc: 0.2763 - val_loss: 11.8633 - val_acc: 0.2793\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.8084 - acc: 0.2768 - val_loss: 11.8548 - val_acc: 0.2795\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.8032 - acc: 0.2773 - val_loss: 11.8640 - val_acc: 0.2736\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7977 - acc: 0.2777 - val_loss: 11.8428 - val_acc: 0.2795\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7946 - acc: 0.2771 - val_loss: 11.8788 - val_acc: 0.2728\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7836 - acc: 0.2794 - val_loss: 11.8396 - val_acc: 0.2806\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7822 - acc: 0.2792 - val_loss: 11.8906 - val_acc: 0.2608\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7787 - acc: 0.2787 - val_loss: 11.8354 - val_acc: 0.2771\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7761 - acc: 0.2793 - val_loss: 11.8250 - val_acc: 0.2803\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7679 - acc: 0.2802 - val_loss: 11.8478 - val_acc: 0.2728\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7676 - acc: 0.2799 - val_loss: 11.8216 - val_acc: 0.2786\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7637 - acc: 0.2794 - val_loss: 11.9270 - val_acc: 0.2487\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7606 - acc: 0.2802 - val_loss: 11.8115 - val_acc: 0.2815\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7574 - acc: 0.2805 - val_loss: 11.8097 - val_acc: 0.2805\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7545 - acc: 0.2806 - val_loss: 11.8147 - val_acc: 0.2795\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7500 - acc: 0.2810 - val_loss: 11.8310 - val_acc: 0.2717\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7485 - acc: 0.2805 - val_loss: 11.8048 - val_acc: 0.2799\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7473 - acc: 0.2808 - val_loss: 11.8585 - val_acc: 0.2610\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 11.7426 - acc: 0.2809 - val_loss: 10.5821 - val_acc: 0.2495\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 2.6357 - acc: 0.3208 - val_loss: 2.3940 - val_acc: 0.3336\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 3.3585 - acc: 0.3404 - val_loss: 6.2278 - val_acc: 0.2928\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.2062 - acc: 0.2087 - val_loss: 14.6427 - val_acc: 0.1869\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 4s 76us/step - loss: 14.8873 - acc: 0.1634 - val_loss: 13.1015 - val_acc: 0.2511\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 14.7959 - acc: 0.1422 - val_loss: 13.9185 - val_acc: 0.1784\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6090 - acc: 0.1791 - val_loss: 13.6950 - val_acc: 0.1437\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5043 - acc: 0.1786 - val_loss: 13.6601 - val_acc: 0.1833\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4225 - acc: 0.1838 - val_loss: 13.1623 - val_acc: 0.1838\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4832 - acc: 0.1841 - val_loss: 13.5916 - val_acc: 0.1828\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5337 - acc: 0.1834 - val_loss: 13.5341 - val_acc: 0.1841\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.1693 - acc: 0.1813 - val_loss: 13.6244 - val_acc: 0.1792\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6760 - acc: 0.1799 - val_loss: 12.6180 - val_acc: 0.1911\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6130 - acc: 0.1801 - val_loss: 13.6740 - val_acc: 0.1771\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4302 - acc: 0.1824 - val_loss: 13.6303 - val_acc: 0.1832\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.7182 - acc: 0.1721 - val_loss: 13.7777 - val_acc: 0.1806\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.7216 - acc: 0.1802 - val_loss: 14.1343 - val_acc: 0.1490\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6062 - acc: 0.1871 - val_loss: 13.6907 - val_acc: 0.1815\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5621 - acc: 0.1892 - val_loss: 13.6727 - val_acc: 0.1812\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4862 - acc: 0.1931 - val_loss: 13.6505 - val_acc: 0.1804\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4857 - acc: 0.1911 - val_loss: 13.6023 - val_acc: 0.1851\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 13.4324 - acc: 0.1939 - val_loss: 13.5636 - val_acc: 0.1855\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.3927 - acc: 0.1937 - val_loss: 13.5616 - val_acc: 0.1841\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.3177 - acc: 0.1920 - val_loss: 12.9115 - val_acc: 0.1881\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.1769 - acc: 0.1892 - val_loss: 13.7917 - val_acc: 0.1809\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5868 - acc: 0.1867 - val_loss: 13.6065 - val_acc: 0.1842\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4381 - acc: 0.1924 - val_loss: 13.5616 - val_acc: 0.1837\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.3174 - acc: 0.1909 - val_loss: 12.4649 - val_acc: 0.2195\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.0313 - acc: 0.1972 - val_loss: 14.3388 - val_acc: 0.1382\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6505 - acc: 0.1840 - val_loss: 13.6729 - val_acc: 0.1822\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5967 - acc: 0.1836 - val_loss: 13.6283 - val_acc: 0.1826\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.3989 - acc: 0.1895 - val_loss: 13.5855 - val_acc: 0.1823\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4964 - acc: 0.1886 - val_loss: 13.7126 - val_acc: 0.1829\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6053 - acc: 0.1870 - val_loss: 13.6612 - val_acc: 0.1844\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5249 - acc: 0.1910 - val_loss: 13.6510 - val_acc: 0.1844\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5047 - acc: 0.1917 - val_loss: 13.6279 - val_acc: 0.1846\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4728 - acc: 0.1930 - val_loss: 13.6503 - val_acc: 0.1812\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5583 - acc: 0.1862 - val_loss: 13.6342 - val_acc: 0.1818\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5033 - acc: 0.1880 - val_loss: 13.6378 - val_acc: 0.1804\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5574 - acc: 0.1830 - val_loss: 13.6085 - val_acc: 0.1800\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.9790 - acc: 0.2031 - val_loss: 13.3702 - val_acc: 0.1788\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4909 - acc: 0.1872 - val_loss: 13.8758 - val_acc: 0.1772\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 13.7013 - acc: 0.1825 - val_loss: 13.6811 - val_acc: 0.1833\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6490 - acc: 0.1833 - val_loss: 13.6855 - val_acc: 0.1818\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 13.5835 - acc: 0.1868 - val_loss: 13.6763 - val_acc: 0.1832\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 13.6187 - acc: 0.1847 - val_loss: 13.6567 - val_acc: 0.1834\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 13.6652 - acc: 0.1819 - val_loss: 13.6380 - val_acc: 0.1836\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 13.6312 - acc: 0.1832 - val_loss: 13.6218 - val_acc: 0.1835\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 13.5986 - acc: 0.1840 - val_loss: 13.3545 - val_acc: 0.1872\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.8131 - acc: 0.2198 - val_loss: 12.5596 - val_acc: 0.2415\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 12.9384 - acc: 0.2188 - val_loss: 13.7417 - val_acc: 0.1815\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6820 - acc: 0.1834 - val_loss: 14.0226 - val_acc: 0.1563\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6556 - acc: 0.1829 - val_loss: 13.6361 - val_acc: 0.1836\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6313 - acc: 0.1832 - val_loss: 13.6203 - val_acc: 0.1833\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6209 - acc: 0.1831 - val_loss: 13.7801 - val_acc: 0.1725\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.6108 - acc: 0.1835 - val_loss: 13.6050 - val_acc: 0.1838\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 13.6021 - acc: 0.1837 - val_loss: 13.6058 - val_acc: 0.1832\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 13.5930 - acc: 0.1839 - val_loss: 13.5889 - val_acc: 0.1838\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5905 - acc: 0.1833 - val_loss: 13.5829 - val_acc: 0.1838\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5740 - acc: 0.1839 - val_loss: 13.5763 - val_acc: 0.1843\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5709 - acc: 0.1838 - val_loss: 13.5966 - val_acc: 0.1821\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5563 - acc: 0.1845 - val_loss: 13.5945 - val_acc: 0.1811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5551 - acc: 0.1839 - val_loss: 13.5740 - val_acc: 0.1825\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5508 - acc: 0.1835 - val_loss: 13.5694 - val_acc: 0.1824\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5432 - acc: 0.1841 - val_loss: 13.5555 - val_acc: 0.1834\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5336 - acc: 0.1842 - val_loss: 13.5903 - val_acc: 0.1801\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5254 - acc: 0.1847 - val_loss: 13.5638 - val_acc: 0.1816\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5226 - acc: 0.1842 - val_loss: 13.5407 - val_acc: 0.1829\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 13.5184 - acc: 0.1840 - val_loss: 13.5239 - val_acc: 0.1840\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5086 - acc: 0.1844 - val_loss: 13.5450 - val_acc: 0.1818\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.5090 - acc: 0.1840 - val_loss: 13.5101 - val_acc: 0.1837\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4973 - acc: 0.1842 - val_loss: 13.5210 - val_acc: 0.1829\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4906 - acc: 0.1844 - val_loss: 13.5379 - val_acc: 0.1798\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4824 - acc: 0.1843 - val_loss: 13.4894 - val_acc: 0.1839\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4761 - acc: 0.1846 - val_loss: 13.4798 - val_acc: 0.1840\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4695 - acc: 0.1843 - val_loss: 13.4759 - val_acc: 0.1839\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 13.4625 - acc: 0.1841 - val_loss: 13.4744 - val_acc: 0.1833\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4541 - acc: 0.1841 - val_loss: 13.5065 - val_acc: 0.1767\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4481 - acc: 0.1841 - val_loss: 13.4599 - val_acc: 0.1829\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4418 - acc: 0.1836 - val_loss: 13.4500 - val_acc: 0.1840\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4319 - acc: 0.1842 - val_loss: 13.4387 - val_acc: 0.1840\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4282 - acc: 0.1835 - val_loss: 13.4324 - val_acc: 0.1840\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4223 - acc: 0.1838 - val_loss: 13.4294 - val_acc: 0.1841\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4172 - acc: 0.1837 - val_loss: 13.4571 - val_acc: 0.1779\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4105 - acc: 0.1839 - val_loss: 13.4344 - val_acc: 0.1816\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4077 - acc: 0.1832 - val_loss: 13.4340 - val_acc: 0.1801\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.4018 - acc: 0.1841 - val_loss: 13.4134 - val_acc: 0.1834\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.3997 - acc: 0.1832 - val_loss: 13.4077 - val_acc: 0.1843\n"
     ]
    }
   ],
   "source": [
    "network_l1 = models.Sequential()\n",
    "network_l1.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,), kernel_regularizer=regularizers.l1(0.001)))\n",
    "network_l1.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1(0.001)))\n",
    "network_l1.add(layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1(0.001)))\n",
    "network_l1.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1(0.001)))\n",
    "network_l1.add(layers.Dense(10, activation='softmax'))\n",
    "network_l1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_l1 = network_l1.fit(train_images, train_labels,validation_data=(valid_images,valid_labels), epochs=200, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 501,898\n",
      "Trainable params: 501,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network_l1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.3213 - acc: 0.1115 - val_loss: 14.2355 - val_acc: 0.1168\n"
     ]
    }
   ],
   "source": [
    "network_l2 = models.Sequential()\n",
    "network_l2.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,), kernel_regularizer=regularizers.l2(0.001)))\n",
    "network_l2.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "network_l2.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "network_l2.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "network_l2.add(layers.Dense(10, activation='softmax'))\n",
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_l2 = network.fit(train_images, train_labels,validation_data=(valid_images,valid_labels), epochs=200, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 501,898\n",
      "Trainable params: 501,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network_l2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss_org = result_org.history['val_loss']\n",
    "val_loss_dropout = result_dropout.history['val_loss']\n",
    "val_loss_l1 = result_l1.history['val_loss']\n",
    "val_loss_l2 = result_l2.history['val_loss']\n",
    "plt.plot(val_loss_org)\n",
    "plt.plot(val_loss_dropout)\n",
    "plt.plot(val_loss_l1)\n",
    "plt.plot(val_loss_l2)\n",
    "plt.legend(['val_loss_org', 'val_loss_dropout', 'val_loss_l1', 'val_loss_l2'])\n",
    "plt.title('The validation loss for the initial/dropout/L1/L2 model over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model appears to perform the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /software/Anaconda3-5.0.1-el7-x86_64/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /software/Anaconda3-5.0.1-el7-x86_64/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.7649 - acc: 0.6585 - val_loss: 1.0275 - val_acc: 0.7803\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.2435 - acc: 0.6675 - val_loss: 3.6329 - val_acc: 0.6712\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.9670 - acc: 0.6780 - val_loss: 3.1512 - val_acc: 0.7344\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 4.3288 - acc: 0.6796 - val_loss: 4.9279 - val_acc: 0.6458\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 4.1463 - acc: 0.7054 - val_loss: 3.9059 - val_acc: 0.7276\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.6042 - acc: 0.7451 - val_loss: 4.4285 - val_acc: 0.6954\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.6265 - acc: 0.7514 - val_loss: 4.8467 - val_acc: 0.6684\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.5883 - acc: 0.7574 - val_loss: 3.6233 - val_acc: 0.7496\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.5347 - acc: 0.7642 - val_loss: 4.6052 - val_acc: 0.6883\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.6040 - acc: 0.7624 - val_loss: 3.5367 - val_acc: 0.7650\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.5911 - acc: 0.7653 - val_loss: 4.6879 - val_acc: 0.6939\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.4792 - acc: 0.7738 - val_loss: 3.0657 - val_acc: 0.8028\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.4313 - acc: 0.7781 - val_loss: 2.9018 - val_acc: 0.8130\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.5396 - acc: 0.7722 - val_loss: 3.1601 - val_acc: 0.7990\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.5191 - acc: 0.7744 - val_loss: 5.3015 - val_acc: 0.6605\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.5702 - acc: 0.7713 - val_loss: 3.5922 - val_acc: 0.7703\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.4573 - acc: 0.7794 - val_loss: 3.4381 - val_acc: 0.7807\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.5735 - acc: 0.7729 - val_loss: 4.0286 - val_acc: 0.7443\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.5776 - acc: 0.7731 - val_loss: 3.1468 - val_acc: 0.8009\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.5162 - acc: 0.7771 - val_loss: 5.2294 - val_acc: 0.6699\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.5671 - acc: 0.7745 - val_loss: 3.7891 - val_acc: 0.7591\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.5695 - acc: 0.7747 - val_loss: 4.3849 - val_acc: 0.7217\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.6115 - acc: 0.7722 - val_loss: 3.7254 - val_acc: 0.7636\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.5339 - acc: 0.7777 - val_loss: 2.8419 - val_acc: 0.8214\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.4899 - acc: 0.7802 - val_loss: 3.9913 - val_acc: 0.7493\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.6483 - acc: 0.7705 - val_loss: 4.1452 - val_acc: 0.7391\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.6890 - acc: 0.7683 - val_loss: 2.9599 - val_acc: 0.8142\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.7362 - acc: 0.7653 - val_loss: 4.3253 - val_acc: 0.7277\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.6929 - acc: 0.7683 - val_loss: 3.9064 - val_acc: 0.7545\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.6212 - acc: 0.7726 - val_loss: 3.6221 - val_acc: 0.7717\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.5645 - acc: 0.7767 - val_loss: 3.0239 - val_acc: 0.8106\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.6202 - acc: 0.7735 - val_loss: 3.8338 - val_acc: 0.7594\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.6082 - acc: 0.7735 - val_loss: 3.7892 - val_acc: 0.7628\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.6740 - acc: 0.7701 - val_loss: 4.4270 - val_acc: 0.7229\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.5948 - acc: 0.7749 - val_loss: 3.4639 - val_acc: 0.7828\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.7012 - acc: 0.7685 - val_loss: 3.3255 - val_acc: 0.7920\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.7267 - acc: 0.7670 - val_loss: 3.6779 - val_acc: 0.7702\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.7172 - acc: 0.7676 - val_loss: 4.1286 - val_acc: 0.7418\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.7651 - acc: 0.7650 - val_loss: 4.1648 - val_acc: 0.7400\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.9308 - acc: 0.7546 - val_loss: 4.0344 - val_acc: 0.7480\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.6816 - acc: 0.7701 - val_loss: 3.0539 - val_acc: 0.8096\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.6256 - acc: 0.7735 - val_loss: 3.2963 - val_acc: 0.7942\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.7713 - acc: 0.7648 - val_loss: 3.3788 - val_acc: 0.7893\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.6401 - acc: 0.7728 - val_loss: 3.0492 - val_acc: 0.8100\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.7832 - acc: 0.7639 - val_loss: 3.7539 - val_acc: 0.7661\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.8433 - acc: 0.7601 - val_loss: 3.6030 - val_acc: 0.7752\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.8241 - acc: 0.7614 - val_loss: 3.3427 - val_acc: 0.7916\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 3.7786 - acc: 0.7643 - val_loss: 4.8059 - val_acc: 0.7010\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 3.6635 - acc: 0.7713 - val_loss: 4.0848 - val_acc: 0.7456\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 3.8249 - acc: 0.7615 - val_loss: 6.8660 - val_acc: 0.5720\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 3.8357 - acc: 0.7609 - val_loss: 3.6870 - val_acc: 0.7701\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 3.7922 - acc: 0.7636 - val_loss: 4.1557 - val_acc: 0.7408\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.6998 - acc: 0.7695 - val_loss: 5.0456 - val_acc: 0.6856\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.9707 - acc: 0.7526 - val_loss: 4.0864 - val_acc: 0.7455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.9057 - acc: 0.7566 - val_loss: 4.1858 - val_acc: 0.7392\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.7354 - acc: 0.7671 - val_loss: 4.4283 - val_acc: 0.7242\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.7044 - acc: 0.7691 - val_loss: 4.0864 - val_acc: 0.7452\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.7326 - acc: 0.7673 - val_loss: 3.8605 - val_acc: 0.7599\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.6578 - acc: 0.7720 - val_loss: 5.6356 - val_acc: 0.6490\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.7723 - acc: 0.7651 - val_loss: 3.2136 - val_acc: 0.7998\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.7884 - acc: 0.7639 - val_loss: 4.2376 - val_acc: 0.7361\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.9361 - acc: 0.7547 - val_loss: 3.5367 - val_acc: 0.7796\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.7510 - acc: 0.7663 - val_loss: 3.3388 - val_acc: 0.7915\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.7637 - acc: 0.7656 - val_loss: 3.8692 - val_acc: 0.7591\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.6563 - acc: 0.7723 - val_loss: 3.8931 - val_acc: 0.7577\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.8488 - acc: 0.7603 - val_loss: 3.9972 - val_acc: 0.7515\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.6845 - acc: 0.7707 - val_loss: 3.3114 - val_acc: 0.7937\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.6943 - acc: 0.7701 - val_loss: 3.6742 - val_acc: 0.7715\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.7649 - acc: 0.7656 - val_loss: 3.9338 - val_acc: 0.7553\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.8601 - acc: 0.7598 - val_loss: 3.9065 - val_acc: 0.7565\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.6186 - acc: 0.7748 - val_loss: 4.1184 - val_acc: 0.7441\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.8842 - acc: 0.7584 - val_loss: 3.2581 - val_acc: 0.7974\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.8269 - acc: 0.7618 - val_loss: 4.6294 - val_acc: 0.7118\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.8307 - acc: 0.7615 - val_loss: 5.0072 - val_acc: 0.6886\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 3.6810 - acc: 0.7710 - val_loss: 3.8857 - val_acc: 0.7577\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 3.8850 - acc: 0.7582 - val_loss: 3.5501 - val_acc: 0.7791\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 3.7198 - acc: 0.7687 - val_loss: 3.4260 - val_acc: 0.7870\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 4.1202 - acc: 0.7437 - val_loss: 3.5071 - val_acc: 0.7819\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 3.8954 - acc: 0.7576 - val_loss: 4.6024 - val_acc: 0.7140\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 3.9848 - acc: 0.7523 - val_loss: 3.6292 - val_acc: 0.7743\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.9653 - acc: 0.7534 - val_loss: 4.6172 - val_acc: 0.7133\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 4.3458 - acc: 0.7298 - val_loss: 6.6055 - val_acc: 0.5895\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 5.3774 - acc: 0.6658 - val_loss: 4.7687 - val_acc: 0.7034\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 4.6811 - acc: 0.7091 - val_loss: 3.3655 - val_acc: 0.7908\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 4.1043 - acc: 0.7446 - val_loss: 5.1633 - val_acc: 0.6792\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 4.5610 - acc: 0.7166 - val_loss: 4.0716 - val_acc: 0.7469\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.7562 - acc: 0.7665 - val_loss: 4.3309 - val_acc: 0.7307\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.9197 - acc: 0.7562 - val_loss: 4.2460 - val_acc: 0.7356\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.6055 - acc: 0.7758 - val_loss: 3.9243 - val_acc: 0.7561\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.9315 - acc: 0.7556 - val_loss: 3.9916 - val_acc: 0.7519\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 4.0961 - acc: 0.7454 - val_loss: 4.2095 - val_acc: 0.7383\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.9862 - acc: 0.7520 - val_loss: 4.4566 - val_acc: 0.7229\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.7937 - acc: 0.7641 - val_loss: 5.2774 - val_acc: 0.6723\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 4.1038 - acc: 0.7449 - val_loss: 3.3998 - val_acc: 0.7887\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 4.1314 - acc: 0.7432 - val_loss: 3.5971 - val_acc: 0.7764\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.8911 - acc: 0.7581 - val_loss: 6.2055 - val_acc: 0.6145\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.9685 - acc: 0.7533 - val_loss: 4.1969 - val_acc: 0.7393\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 4.1793 - acc: 0.7403 - val_loss: 4.3646 - val_acc: 0.7287\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.8475 - acc: 0.7607 - val_loss: 4.0018 - val_acc: 0.7507\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.9381 - acc: 0.7554 - val_loss: 3.3000 - val_acc: 0.7951\n",
      "Epoch 101/200\n",
      " 7680/50000 [===>..........................] - ETA: 3s - loss: 3.8603 - acc: 0.7602"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-89c34201f44e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnetwork_org\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnetwork_org\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresult_org\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork_org\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/software/Anaconda3-5.0.1-el7-x86_64/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/software/Anaconda3-5.0.1-el7-x86_64/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/software/Anaconda3-5.0.1-el7-x86_64/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/Anaconda3-5.0.1-el7-x86_64/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/Anaconda3-5.0.1-el7-x86_64/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/Anaconda3-5.0.1-el7-x86_64/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/Anaconda3-5.0.1-el7-x86_64/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/Anaconda3-5.0.1-el7-x86_64/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/Anaconda3-5.0.1-el7-x86_64/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/Anaconda3-5.0.1-el7-x86_64/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "network_org = models.Sequential()\n",
    "network_org.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network_org.add(layers.Dense(512, activation='relu'))\n",
    "# network_org.add(layers.Dense(512, activation='relu'))\n",
    "# network_org.add(layers.Dense(512, activation='relu'))\n",
    "network_org.add(layers.Dense(10, activation='softmax'))\n",
    "network_org.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_org = network_org.fit(train_images, train_labels,validation_data=(valid_images,valid_labels), epochs=200, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.7930 - acc: 0.6578 - val_loss: 2.8803 - val_acc: 0.6146\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 3.8689 - acc: 0.6448 - val_loss: 4.1106 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 6.7988 - acc: 0.5263 - val_loss: 7.9614 - val_acc: 0.4838\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 7.1396 - acc: 0.5314 - val_loss: 6.7406 - val_acc: 0.5653\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 7.1524 - acc: 0.5383 - val_loss: 6.9528 - val_acc: 0.5536\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 7.0643 - acc: 0.5501 - val_loss: 8.8859 - val_acc: 0.4344\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 7.0434 - acc: 0.5532 - val_loss: 6.6976 - val_acc: 0.5786\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 6.9692 - acc: 0.5595 - val_loss: 7.0882 - val_acc: 0.5529\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 6.9555 - acc: 0.5623 - val_loss: 8.4309 - val_acc: 0.4708\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 6.9961 - acc: 0.5602 - val_loss: 7.4977 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 6.9520 - acc: 0.5643 - val_loss: 6.9235 - val_acc: 0.5661\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 6.9419 - acc: 0.5651 - val_loss: 6.6680 - val_acc: 0.5839\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 6.8990 - acc: 0.5683 - val_loss: 7.7469 - val_acc: 0.5142\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 6.9783 - acc: 0.5638 - val_loss: 6.6719 - val_acc: 0.5844\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 6.9694 - acc: 0.5649 - val_loss: 7.2599 - val_acc: 0.5456\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 6.9686 - acc: 0.5650 - val_loss: 6.8988 - val_acc: 0.5698\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 6.9939 - acc: 0.5639 - val_loss: 6.9350 - val_acc: 0.5669\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 6.9804 - acc: 0.5646 - val_loss: 6.8117 - val_acc: 0.5756\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 6.9661 - acc: 0.5658 - val_loss: 7.0622 - val_acc: 0.5596\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 6.9628 - acc: 0.5661 - val_loss: 6.8187 - val_acc: 0.5753\n"
     ]
    }
   ],
   "source": [
    "network_org = models.Sequential()\n",
    "network_org.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network_org.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "# network_org.add(layers.Dense(512, activation='relu'))\n",
    "# network_org.add(layers.Dense(512, activation='relu'))\n",
    "# network_org.add(layers.Dense(512, activation='relu'))\n",
    "network_org.add(layers.Dense(10, activation='softmax'))\n",
    "network_org.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_org = network_org.fit(train_images, train_labels,validation_data=(valid_images,valid_labels), epochs=20, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network_org.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_dropout = models.Sequential()\n",
    "network_dropout.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network_dropout.add(layers.Dropout(0.5))\n",
    "network_dropout.add(layers.Dense(512, activation='relu'))\n",
    "network_dropout.add(layers.Dropout(0.5))\n",
    "network_dropout.add(layers.Dense(512, activation='relu'))\n",
    "network_dropout.add(layers.Dropout(0.5))\n",
    "network_dropout.add(layers.Dense(512, activation='relu'))\n",
    "network_dropout.add(layers.Dropout(0.5))\n",
    "network_dropout.add(layers.Dense(10, activation='softmax'))\n",
    "network_dropout.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_dropout = network_dropout.fit(train_images, train_labels,validation_data=(valid_images,valid_labels), epochs=200, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 29.4562 - acc: 0.1101 - val_loss: 18.5410 - val_acc: 0.1168\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 17.6557 - acc: 0.1034 - val_loss: 17.5428 - val_acc: 0.0918\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 17.0672 - acc: 0.0963 - val_loss: 17.0719 - val_acc: 0.0912\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 16.3921 - acc: 0.1052 - val_loss: 16.3184 - val_acc: 0.0975\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 16.1869 - acc: 0.1032 - val_loss: 16.1665 - val_acc: 0.1018\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 16.1658 - acc: 0.0984 - val_loss: 16.0976 - val_acc: 0.0978\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.8934 - acc: 0.1038 - val_loss: 16.0559 - val_acc: 0.1001\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.9341 - acc: 0.0991 - val_loss: 15.5768 - val_acc: 0.1168\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.8791 - acc: 0.0975 - val_loss: 14.9678 - val_acc: 0.0978\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.8873 - acc: 0.0982 - val_loss: 15.9901 - val_acc: 0.1018\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.8188 - acc: 0.0991 - val_loss: 15.9079 - val_acc: 0.1018\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.7533 - acc: 0.0995 - val_loss: 15.4958 - val_acc: 0.1168\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.7206 - acc: 0.1027 - val_loss: 15.3972 - val_acc: 0.1168\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.7337 - acc: 0.0982 - val_loss: 15.9002 - val_acc: 0.0918\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.5757 - acc: 0.1027 - val_loss: 15.6849 - val_acc: 0.1018\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.5108 - acc: 0.1051 - val_loss: 15.9909 - val_acc: 0.0918\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.6856 - acc: 0.1012 - val_loss: 16.0576 - val_acc: 0.0918\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.7905 - acc: 0.0962 - val_loss: 15.8717 - val_acc: 0.0912\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.6532 - acc: 0.0981 - val_loss: 15.8434 - val_acc: 0.0975\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.6978 - acc: 0.1004 - val_loss: 15.8497 - val_acc: 0.0975\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.6589 - acc: 0.0992 - val_loss: 15.8507 - val_acc: 0.0975\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.7296 - acc: 0.0938 - val_loss: 15.8099 - val_acc: 0.0975\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 15.6416 - acc: 0.0995 - val_loss: 15.9215 - val_acc: 0.0912\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.5894 - acc: 0.0944 - val_loss: 15.7033 - val_acc: 0.1001\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.7170 - acc: 0.0966 - val_loss: 15.8206 - val_acc: 0.0918\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.5658 - acc: 0.0993 - val_loss: 14.4423 - val_acc: 0.1001\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.5812 - acc: 0.0996 - val_loss: 15.7497 - val_acc: 0.1001\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.5913 - acc: 0.0967 - val_loss: 15.8902 - val_acc: 0.0918\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.4882 - acc: 0.0942 - val_loss: 15.7480 - val_acc: 0.1001\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.6683 - acc: 0.0952 - val_loss: 15.1958 - val_acc: 0.0912\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.5653 - acc: 0.1005 - val_loss: 14.8709 - val_acc: 0.0912\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.6039 - acc: 0.0992 - val_loss: 15.6258 - val_acc: 0.1018\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.4032 - acc: 0.0951 - val_loss: 15.7385 - val_acc: 0.1001\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.6365 - acc: 0.1002 - val_loss: 15.6699 - val_acc: 0.1001\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 15.5934 - acc: 0.0983 - val_loss: 15.7414 - val_acc: 0.0918\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.4905 - acc: 0.0926 - val_loss: 15.9709 - val_acc: 0.0912\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.7525 - acc: 0.0944 - val_loss: 15.7888 - val_acc: 0.0918\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.5535 - acc: 0.0983 - val_loss: 15.7567 - val_acc: 0.0918\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.4506 - acc: 0.0954 - val_loss: 15.8292 - val_acc: 0.0912\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.5710 - acc: 0.0981 - val_loss: 15.6187 - val_acc: 0.1018\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.5214 - acc: 0.1018 - val_loss: 15.5932 - val_acc: 0.1001\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.4719 - acc: 0.0994 - val_loss: 15.6826 - val_acc: 0.0918\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.4739 - acc: 0.0996 - val_loss: 15.5113 - val_acc: 0.1001\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.4677 - acc: 0.0967 - val_loss: 15.4509 - val_acc: 0.1001\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 15.4674 - acc: 0.0939 - val_loss: 15.3012 - val_acc: 0.0912\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.5220 - acc: 0.0964 - val_loss: 15.4416 - val_acc: 0.1018\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 15.4675 - acc: 0.0967 - val_loss: 14.5225 - val_acc: 0.1001\n",
      "Epoch 48/200\n",
      " 4096/50000 [=>............................] - ETA: 8s - loss: 15.1505 - acc: 0.1003"
     ]
    }
   ],
   "source": [
    "network_l1 = models.Sequential()\n",
    "network_l1.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,), kernel_regularizer=regularizers.l1(0.001)))\n",
    "network_l1.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l1(0.001)))\n",
    "network_l1.add(layers.Dense(512, activation='relu',kernel_regularizer=regularizers.l1(0.001)))\n",
    "network_l1.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l1(0.001)))\n",
    "network_l1.add(layers.Dense(10, activation='softmax'))\n",
    "network_l1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_l1 = network_l1.fit(train_images, train_labels,validation_data=(valid_images,valid_labels), epochs=200, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_l2 = models.Sequential()\n",
    "network_l2.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,), kernel_regularizer=regularizers.l2(0.001)))\n",
    "network_l2.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "network_l2.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "network_l2.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "network_l2.add(layers.Dense(10, activation='softmax'))\n",
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_l2 = network.fit(train_images, train_labels,validation_data=(valid_images,valid_labels), epochs=200, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_org = result_org.history['val_loss']\n",
    "val_loss_dropout = result_dropout.history['val_loss']\n",
    "val_loss_l1 = result_l1.history['val_loss']\n",
    "val_loss_l2 = result_l2.history['val_loss']\n",
    "plt.plot(val_loss_org)\n",
    "plt.plot(val_loss_dropout)\n",
    "plt.plot(val_loss_l1)\n",
    "plt.plot(val_loss_l2)\n",
    "plt.legend(['val_loss_org', 'val_loss_dropout', 'val_loss_l1', 'val_loss_l2'])\n",
    "plt.title('The validation loss for the initial/dropout/L1/L2 model over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        iv. Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 2.0718 - acc: 0.5519\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 1.2295 - acc: 0.8149\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 0.9919 - acc: 0.8644\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 0.8558 - acc: 0.8874\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 0.7606 - acc: 0.8997\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 0.6921 - acc: 0.9084\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 0.6506 - acc: 0.9106\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 0.6114 - acc: 0.9146\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 0.5888 - acc: 0.9198\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 0.5700 - acc: 0.9214\n"
     ]
    }
   ],
   "source": [
    "network_best = models.Sequential()\n",
    "network_best.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,), kernel_regularizer=regularizers.l2(0.001)))\n",
    "network_best.add(layers.Dropout(0.5))\n",
    "network_best.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "network_best.add(layers.Dropout(0.5))\n",
    "network_best.add(layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "network_best.add(layers.Dropout(0.5))\n",
    "network_best.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "network_best.add(layers.Dropout(0.5))\n",
    "network_best.add(layers.Dense(10, activation='softmax'))\n",
    "network_best.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_best = network_best.fit(train_images, train_labels, epochs=10, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_best.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 93us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4371046806335449, 0.9525]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_best.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcuate the test set loss and accuracy. How well does your model perform to the baseline from chapter 2.1 in the book? 0.9785"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Scalar regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) =boston_housing.load_data()\n",
    "\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "k = 10\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate([train_data[:i * num_val_samples], train_data[(i + 1) * num_val_samples:]], axis=0)\n",
    "    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples], train_targets[(i + 1) * num_val_samples:]],axis=0)\n",
    "    model = build_model()\n",
    "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.9):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "    if smoothed_points:\n",
    "        previous = smoothed_points[-1]\n",
    "        smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "        smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "    \n",
    "smooth_mae_history = smooth_curve(average_mae_history[10:])\n",
    "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.fit(train_data, train_targets, epochs=80, batch_size=16, verbose=0)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
